{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SPRINT 4.** Projecte individual- Recol·lecció de dades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Tasca 4.1***\n",
    "- Objectius: Extreure dades d'una API i mitjançant Web Scraping a Python.\n",
    "- Lliurament: Utilitza un fitxer de Jupyter Notebook amb l'script a Python. Recorda utilitzar Markdown per millorar la comprensió del codi. Puja'l al teu repositori de GitHub i insereix l'URL per a la seva avaluació. Recorda que el repositori ha d'estar públic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercici 1. Consumir una API\n",
    "Selecciona una API pública i extreu dades utilitzant Python.\n",
    "\n",
    "Pasos seguidos:\n",
    "1. Crear un email temporal para solicitar la API_KEY ya que el Jupyter notebook quedará como público\n",
    "2. Solicitar la API_KEY en la web https://openweathermap.org/price para acceso gratuito con el email temporal.\n",
    "3. Esperar 2 horas a que se active la API_KEY (en realidad tardó mas)\n",
    "4. Consumir la API según la documentación de la web: https://openweathermap.org/api\n",
    "5. Tener en cuenta que estamos con un cuenta gratuita, por lo que tanto los datos como el número de accesos son limitados\n",
    "6. Como ejemplo, se presenta la meteorologia actual en las capitales catalanas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tiempo en las capitales catalanas:\n",
      "  Barcelona (ES): T: 14.0 ºC, P: 1024 hPa, HR: 67 %\n",
      "  Girona (ES): T: 10.9 ºC, P: 1023 hPa, HR: 86 %\n",
      "  Tarragona (ES): T: 11.9 ºC, P: 1024 hPa, HR: 81 %\n",
      "  Lleida (ES): T: 9.1 ºC, P: 1024 hPa, HR: 90 %\n"
     ]
    }
   ],
   "source": [
    "# Datos del tiempo en las capitales catalanas\n",
    "# Consumimos la API para cada una de las ciudades de la lista 'cities'\n",
    "# Cada una de la respuestas es un diccionario, que se almacena secuencialmente en la lista 'weather'\n",
    "# Presentamos los datos básicos del tiempo, comprobando que la consulta a la API fue correcta ('.cod' == 200) \n",
    "\n",
    "# Se probó tambien con latitud/longitud, pero finalmente se utilizaron los nombres de las ciudades\n",
    "# https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={API key}\n",
    "\n",
    "import requests\n",
    "\n",
    "API_key = \"622fbdfe465131940702e4e9b3c12ddf\"\n",
    "cities = [\"Barcelona\", \"Girona\", \"Tarragona\", \"Lleida\"]\n",
    "weather = []\n",
    "\n",
    "for city in cities:\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_key}\"\n",
    "    response = requests.get(url)\n",
    "    weather.append(response.json())\n",
    "\n",
    "print(\"El tiempo en las capitales catalanas:\")\n",
    "for w in weather:\n",
    "    if w['cod'] == 200:\n",
    "        print(f\"  {w['name']} ({w['sys']['country']}): T: {w['main']['temp'] - 273.15:.1f} ºC, P: {w['main']['pressure']} hPa, HR: {w['main']['humidity']} %\")\n",
    "    else:\n",
    "        print(f\"*** Error en la solicitud ({response.text}) ***\")\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coord': {'lon': 2.159, 'lat': 41.3888},\n",
       " 'weather': [{'id': 802,\n",
       "   'main': 'Clouds',\n",
       "   'description': 'scattered clouds',\n",
       "   'icon': '03n'}],\n",
       " 'base': 'stations',\n",
       " 'main': {'temp': 290.71,\n",
       "  'feels_like': 290.66,\n",
       "  'temp_min': 289.51,\n",
       "  'temp_max': 291.93,\n",
       "  'pressure': 1018,\n",
       "  'humidity': 82,\n",
       "  'sea_level': 1018,\n",
       "  'grnd_level': 1011},\n",
       " 'visibility': 8000,\n",
       " 'wind': {'speed': 5.14, 'deg': 230},\n",
       " 'clouds': {'all': 40},\n",
       " 'dt': 1732560154,\n",
       " 'sys': {'type': 2,\n",
       "  'id': 18549,\n",
       "  'country': 'ES',\n",
       "  'sunrise': 1732517519,\n",
       "  'sunset': 1732551918},\n",
       " 'timezone': 3600,\n",
       " 'id': 3128760,\n",
       " 'name': 'Barcelona',\n",
       " 'cod': 200}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda de apoyo para comprobar la estructura del fichero json\n",
    "weather[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercici 2. Obtenir dades amb Web Scraping\n",
    "Selecciona un lloc web i extreu dades utilitzant la tècnica de Web Scraping a Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pasos seguidos han sido:\n",
    "1. Se elije la web 'https://tarifaluzhora.es/' que presenta los precios de la luz del mercado regulado.\n",
    "2. Segun la propia web, la fuente de los datos es REE (Red Electrica de España).\n",
    "3. Los datos se presentan en un formato claro y amigable que permite comprobar fácilmente si el _scraping_ es correcto.\n",
    "4. Se comprueba el fichero 'robots.txt' para verificar que tenemos permiso para capturar datos de la página principal.\n",
    "5. Utilizamos la libreria BeautifulSoup para realizar el _scraping_ de las tarifas.\n",
    "6. Se presentan los datos en pantalla y se comprueba que son correctos con la página web.\n",
    "7. Se añaden los datos a un fichero CSV en formato fecha, hora0, precio0, hora1, precio1...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precio de la tarifa de luz por horas HOY | 26 Noviembre 2024\n",
      "==============================================================\n",
      "       00:00 - 01:00   :   0.1718 €/kWh\n",
      "       01:00 - 02:00   :   0.17 €/kWh\n",
      "       02:00 - 03:00   :   0.166 €/kWh\n",
      "       03:00 - 04:00   :   0.1628 €/kWh\n",
      "       04:00 - 05:00   :   0.1662 €/kWh\n",
      "       05:00 - 06:00   :   0.172 €/kWh\n",
      "       06:00 - 07:00   :   0.175 €/kWh\n",
      "       07:00 - 08:00   :   0.1786 €/kWh\n",
      "       08:00 - 09:00   :   0.2133 €/kWh\n",
      "       09:00 - 10:00   :   0.2003 €/kWh\n",
      "       10:00 - 11:00   :   0.2439 €/kWh\n",
      "       11:00 - 12:00   :   0.2404 €/kWh\n",
      "       12:00 - 13:00   :   0.2377 €/kWh\n",
      "       13:00 - 14:00   :   0.2369 €/kWh\n",
      "       14:00 - 15:00   :   0.188 €/kWh\n",
      "       15:00 - 16:00   :   0.1925 €/kWh\n",
      "       16:00 - 17:00   :   0.1932 €/kWh\n",
      "       17:00 - 18:00   :   0.2031 €/kWh\n",
      "       18:00 - 19:00   :   0.2684 €/kWh\n",
      "       19:00 - 20:00   :   0.2628 €/kWh\n",
      "       20:00 - 21:00   :   0.2612 €/kWh\n",
      "       21:00 - 22:00   :   0.2577 €/kWh\n",
      "       22:00 - 23:00   :   0.2006 €/kWh\n",
      "       23:00 - 24:00   :   0.1967 €/kWh\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://tarifaluzhora.es/\"\n",
    "\n",
    "page = requests.get(URL)\n",
    "if page.status_code != 200:\n",
    "    print(\"Error en la lectura de la web '{URL}'. Codigo: {page.status_code}\")\n",
    "\n",
    "else:\n",
    "\n",
    "    ''' Leer pagina web '''\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    ''' Decodificar datos leidos y presentar en pantalla '''    \n",
    "    titulo = soup.find(\"title\").text\n",
    "    horario = soup.find_all(\"span\", itemprop=\"description\")\n",
    "    precio = soup.find_all(\"span\", itemprop=\"price\")\n",
    "    print(\"\", titulo[:-2])\n",
    "    print(\"=\"*len(titulo))\n",
    "    for i in range(len(horario)):\n",
    "        print(\" \"*6, horario[i].text, \"  :  \", precio[i].text.expandtabs(0).replace('\\n', ' '))\n",
    "\n",
    "    ''' Añadir datos leidos en una nueva linea en fichero CSV '''\n",
    "    FILENAME = \"precios_luz.csv\"\n",
    "    with open(FILENAME, 'a') as file:\n",
    "        t = f\"{titulo.split('|')[1].strip()[:-2]}\"\n",
    "        file.write(t)\n",
    "        for i in range(len(horario)):\n",
    "            h = horario[i].text\n",
    "            p = precio[i].text.expandtabs(0).replace('\\n', ' ')\n",
    "            hp = \", \" + h + \", \" + p\n",
    "            file.write(hp)\n",
    "        file.write(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
